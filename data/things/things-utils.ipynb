{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from semantic_memory import vsm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "with open(\"spose_embedding_66d_sorted.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        vector = [float(x) for x in line.split()]\n",
    "        embeddings.append(vector)\n",
    "\n",
    "embeddings = torch.tensor(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = open(\"unique_id.txt\", \"r\").readlines()\n",
    "vocab = [x.strip() for x in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "things = vsm.VectorSpaceModel(\"THINGS 66d\")\n",
    "things.load_vectors_from_tensor(embeddings, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rat', 0.98600834608078),\n",
       " ('warthog', 0.9813143014907837),\n",
       " ('chipmunk', 0.980313241481781),\n",
       " ('rhinoceros', 0.9765945076942444),\n",
       " ('bear', 0.9756324291229248),\n",
       " ('fox', 0.9725315570831299),\n",
       " ('chinchilla', 0.9714034795761108),\n",
       " ('cougar', 0.9698286652565002),\n",
       " ('coyote', 0.9682605266571045),\n",
       " ('mongoose', 0.9668706655502319)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "things.neighbor(\"mouse1\",k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_similarity(v1, v2):\n",
    "    return torch.dot(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.5295)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_similarity(things(\"mouse1\").squeeze(0), things(\"rat\").squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding2sim(embedding):\n",
    "    # Convert embedding to similarity matrix\n",
    "    n_objects = embedding.size(0)\n",
    "\n",
    "    # Compute the similarity matrix\n",
    "    sim = torch.mm(embedding, embedding.T)\n",
    "    esim = torch.exp(sim)\n",
    "\n",
    "    print(\"Initialized similarities\")\n",
    "\n",
    "    # Initialize the cp matrix\n",
    "    cp = torch.zeros(n_objects, n_objects)\n",
    "\n",
    "    print(\"Initialized matrix\")\n",
    "\n",
    "    # Compute the similarity matrix\n",
    "    for i in range(n_objects):\n",
    "        for j in trange(i + 1, n_objects):\n",
    "            ctmp = torch.zeros(n_objects)\n",
    "            for k in range(n_objects):\n",
    "                if k == i or k == j:\n",
    "                    continue\n",
    "                ctmp[k] = esim[i, j] / (esim[i, j] + esim[i, k] + esim[j, k])\n",
    "            cp[i, j] = torch.sum(ctmp)\n",
    "\n",
    "    # Normalize the cp matrix\n",
    "    cp = cp / (n_objects - 2)\n",
    "    cp = cp + cp.T  # Make the matrix symmetric\n",
    "    cp[torch.eye(n_objects).bool()] = 1  # Set the diagonal to 1\n",
    "\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3435462"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1854 * 1853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1854, 1854])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(things.embeddings, things.embeddings.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized similarities\n",
      "Initialized matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 746/1853 [00:12<00:18, 59.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spose_sim \u001b[38;5;241m=\u001b[39m \u001b[43membedding2sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m, in \u001b[0;36membedding2sim\u001b[0;34m(embedding)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m i \u001b[38;5;129;01mor\u001b[39;00m k \u001b[38;5;241m==\u001b[39m j:\n\u001b[1;32m     22\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m             ctmp[k] \u001b[38;5;241m=\u001b[39m esim[i, j] \u001b[38;5;241m/\u001b[39m (esim[i, j] \u001b[38;5;241m+\u001b[39m esim[i, k] \u001b[38;5;241m+\u001b[39m esim[j, k])\n\u001b[1;32m     24\u001b[0m         cp[i, j] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(ctmp)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Normalize the cp matrix\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "spose_sim = embedding2sim(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, n_objects):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# c+=1\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# ctmp = torch.zeros(n_objects)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_objects):\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m i \u001b[38;5;129;01mor\u001b[39;00m k \u001b[38;5;241m==\u001b[39m j:\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         c\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_objects = embeddings.size(0)\n",
    "c=0\n",
    "for i in range(n_objects):\n",
    "    for j in range(i + 1, n_objects):\n",
    "        # c+=1\n",
    "        # ctmp = torch.zeros(n_objects)\n",
    "        for k in range(n_objects):\n",
    "            if k == i or k == j:\n",
    "                continue\n",
    "            c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6372783864"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1854 * 1854 * 1854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding2sim_optimized(embedding):\n",
    "    # Number of objects\n",
    "    n_objects = embedding.size(0)\n",
    "\n",
    "    # Compute the similarity matrix\n",
    "    sim = torch.mm(embedding, embedding.T)\n",
    "    esim = torch.exp(sim)\n",
    "\n",
    "    # Initialize the cp matrix\n",
    "    cp = torch.zeros(n_objects, n_objects)\n",
    "\n",
    "    # Use broadcasting to create a mask that avoids diagonal elements\n",
    "    mask = ~torch.eye(n_objects, dtype=bool, device=embedding.device)\n",
    "\n",
    "    # Calculate for all pairs (i, j)\n",
    "    for i in trange(n_objects):\n",
    "        # For each i, calculate the contribution to all j simultaneously\n",
    "        esim_i = esim[i, :].unsqueeze(1)\n",
    "        denom = esim_i + esim + esim[i, i].unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        # Avoid self-interactions by masking\n",
    "        ctmp = esim[i, :] / denom\n",
    "        ctmp[~mask] = 0\n",
    "\n",
    "        # Sum across all k for each (i, j)\n",
    "        cp[i, :] = ctmp.sum(dim=0)\n",
    "\n",
    "    # Normalize the cp matrix\n",
    "    cp = cp / (n_objects - 2)\n",
    "    cp = cp + cp.T  # Make the matrix symmetric\n",
    "    cp[torch.eye(n_objects).bool()] = 1  # Set the diagonal to 1\n",
    "\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1854/1854 [00:06<00:00, 305.25it/s]\n"
     ]
    }
   ],
   "source": [
    "spose_sim_optimized = embedding2sim_optimized(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0065, 0.0042,  ..., 0.9605, 0.0067, 0.0186],\n",
       "        [0.0065, 1.0000, 0.1884,  ..., 0.0114, 0.1025, 0.0135],\n",
       "        [0.0042, 0.1884, 1.0000,  ..., 0.0089, 0.0688, 0.0057],\n",
       "        ...,\n",
       "        [0.9605, 0.0114, 0.0089,  ..., 1.0000, 0.0072, 0.0119],\n",
       "        [0.0067, 0.1025, 0.0688,  ..., 0.0072, 1.0000, 0.0071],\n",
       "        [0.0186, 0.0135, 0.0057,  ..., 0.0119, 0.0071, 1.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spose_sim_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1026"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "things.vocab2idx['mouse1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9245)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spose_sim_optimized[1026, 1285]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([70,  0,  2,  ..., 20,  1, 23])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(spose_sim_optimized > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding2sim_optimized_corrected(embedding):\n",
    "    # Number of objects\n",
    "    n_objects = embedding.size(0)\n",
    "\n",
    "    # Compute the similarity matrix\n",
    "    sim = torch.mm(embedding, embedding.T)\n",
    "    esim = torch.exp(sim)\n",
    "\n",
    "    # Initialize the cp matrix\n",
    "    cp = torch.zeros(n_objects, n_objects)  \n",
    "\n",
    "    for i in range(n_objects):\n",
    "        # Compute similarity scores for all pairs (i, j) where j > i\n",
    "        esim_ij = esim[i, i+1:]  # esim[i, j] for all j > i\n",
    "        esim_i = esim[i, :]      # esim[i, k] for all k\n",
    "        esim_j = esim[i+1:, :]   # esim[j, k] for all k where j > i\n",
    "        \n",
    "        if esim_ij.numel() == 0:\n",
    "            continue  # Skip if there are no valid j > i\n",
    "        \n",
    "        # Calculate ctmp for all j > i at once\n",
    "        denom = esim_ij.unsqueeze(1) + esim_i[i+1:].unsqueeze(0) + esim_j[:, i+1:]\n",
    "        ctmp = esim_ij.unsqueeze(1) / denom\n",
    "        \n",
    "        # Exclude contributions where k == i or k == j\n",
    "        ctmp[:, 0] = 0  # Exclude the first element corresponding to the current i\n",
    "        for j_idx in range(ctmp.size(0)):\n",
    "            ctmp[j_idx, j_idx] = 0  # Exclude j == k (diagonal of ctmp)\n",
    "\n",
    "        # Sum ctmp and store in cp\n",
    "        cp[i, i+1:] = ctmp.sum(dim=1)\n",
    "\n",
    "    # Normalize the cp matrix\n",
    "    cp = cp / (n_objects - 2)\n",
    "    cp = cp + cp.T  # Make the matrix symmetric\n",
    "    cp[torch.eye(n_objects).bool()] = 1  # Set the diagonal to 1\n",
    "\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spose_sim_optimized_corrected = embedding2sim_optimized_corrected(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.0873, 0.1030, 0.4509, 0.0986, 0.1185, 0.1033, 0.1188, 0.2154,\n",
       "        0.1588])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spose_sim_optimized_corrected[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding2sim(embedding):\n",
    "    # This function converts an embedding to a similarity matrix\n",
    "    n_objects = embedding.shape[0]\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    sim = torch.matmul(embedding, embedding.t())\n",
    "    esim = torch.exp(sim)\n",
    "    \n",
    "    # Create mask to exclude i==k and j==k cases\n",
    "    mask = torch.ones(n_objects, n_objects, n_objects, dtype=torch.bool)\n",
    "    mask.diagonal(dim1=0, dim2=1).fill_(False)\n",
    "    mask.diagonal(dim1=0, dim2=2).fill_(False)\n",
    "    \n",
    "    # Compute cp matrix\n",
    "    i, j = torch.triu_indices(n_objects, n_objects, offset=1)\n",
    "    esim_ij = esim[i, j].unsqueeze(-1)\n",
    "    esim_ik = esim[i].unsqueeze(1)\n",
    "    esim_jk = esim[j].unsqueeze(1)\n",
    "    \n",
    "    ctmp = esim_ij / (esim_ij + esim_ik + esim_jk)\n",
    "    ctmp = ctmp.masked_fill(~mask[i, j], 0)\n",
    "    \n",
    "    cp = torch.zeros(n_objects, n_objects)\n",
    "    cp[i, j] = ctmp.sum(dim=-1) / (n_objects - 2)\n",
    "    \n",
    "    # Make cp symmetric\n",
    "    cp = cp + cp.t()\n",
    "    cp.diagonal().fill_(1)\n",
    "    \n",
    "    return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:83] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 21881648030485176 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spose_sim \u001b[38;5;241m=\u001b[39m \u001b[43membedding2sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 20\u001b[0m, in \u001b[0;36membedding2sim\u001b[0;34m(embedding)\u001b[0m\n\u001b[1;32m     17\u001b[0m esim_ik \u001b[38;5;241m=\u001b[39m esim[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m esim_jk \u001b[38;5;241m=\u001b[39m esim[j]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m ctmp \u001b[38;5;241m=\u001b[39m esim_ij \u001b[38;5;241m/\u001b[39m (\u001b[43mesim_ij\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mesim_ik\u001b[49m \u001b[38;5;241m+\u001b[39m esim_jk)\n\u001b[1;32m     21\u001b[0m ctmp \u001b[38;5;241m=\u001b[39m ctmp\u001b[38;5;241m.\u001b[39mmasked_fill(\u001b[38;5;241m~\u001b[39mmask[i, j], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m cp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(n_objects, n_objects)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:83] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 21881648030485176 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "spose_sim = embedding2sim(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
