{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/km55359/.conda/envs/kmisra/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "\n",
    "import lexicon\n",
    "import config\n",
    "import utils\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "from semantic_memory import vsm, vsm_utils\n",
    "from nltk.corpus import wordnet as wn\n",
    "from minicons import scorer, cwe\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma2concept(entry):\n",
    "    return lexicon.Concept(\n",
    "        lemma=entry[\"lemma\"],\n",
    "        singular=entry[\"singular\"],\n",
    "        plural=entry[\"plural\"],\n",
    "        article=entry[\"article\"],\n",
    "        generic=entry[\"generic\"],\n",
    "        taxonomic_phrase=entry[\"taxonomic_phrase\"],\n",
    "    )\n",
    "\n",
    "lemma_path = \"../data/things/things-lemmas-annotated.csv\"\n",
    "\n",
    "# read in concepts\n",
    "concepts = defaultdict(lexicon.Concept)\n",
    "with open(lemma_path, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row[\"remove\"] != \"1\":\n",
    "            concepts[row[\"lemma\"]] = lemma2concept(row)\n",
    "\n",
    "things_senses = set()\n",
    "with open(\"../data/things/things-senses-annotated.csv\", \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row[\"sense\"] != \"-\":\n",
    "            senses = row['sense'].split(\"&\")\n",
    "            for sense in senses:\n",
    "                things_senses.add(sense)\n",
    "\n",
    "triple_path = \"../data/things/things-triples.csv\"\n",
    "triples = utils.read_csv_dict(triple_path)\n",
    "\n",
    "anchors = set()\n",
    "hyponyms = set()\n",
    "anchor_children = defaultdict(set)\n",
    "concept_universe = set()\n",
    "\n",
    "for triple in triples:\n",
    "    hypernym = triple[\"hypernym\"]\n",
    "    hyponym = triple[\"hyponym\"]\n",
    "    anchor = triple[\"anchor\"]\n",
    "\n",
    "    anchors.add(anchor)\n",
    "    hyponyms.add(hyponym)\n",
    "    anchor_children[anchor].add(hyponym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concept_words = \n",
    "prop = lexicon.Property(\"daxable\", \"is daxable\", \"are daxable\")\n",
    "\n",
    "# concepts['aardvark'].property_sentence(prop)\n",
    "\n",
    "# concepts['aardvark']\n",
    "concept_space = defaultdict(str)\n",
    "for c, concept in concepts.items():\n",
    "    if concept.generic == \"s\":\n",
    "        concept_space[c] = re.split(r'^(a|an)', concept.article)[-1]\n",
    "    else:\n",
    "        concept_space[c] = concept.plural\n",
    "\n",
    "concept_space = dict(concept_space)\n",
    "\n",
    "# prepare batches\n",
    "\n",
    "query_pairs = [(v,v) for v in concept_space.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7db56490072447083e1a5cb6e7ea152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae690c0d2ab447980abcb2cb10c4ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lm = scorer.IncrementalLMScorer(\"mistralai/Mistral-7B-Instruct-v0.2\", \"cuda:0\")\n",
    "lm = cwe.CWE(\"mistralai/Mistral-7B-Instruct-v0.2\", \"cuda:0\")\n",
    "# embs = lm.model.model.embed_tokens.weight.detach().cpu()\n",
    "# vocab = lm.tokenizer.convert_ids_to_tokens(range(len(embs)))\n",
    "\n",
    "# comment this out if saving first\n",
    "# embs, vocab = torch.load(\"../data/embeddings/Mistral-7B-Instruct-v0.2.pt\")\n",
    "\n",
    "# mistral_vsm = vsm.VectorSpaceModel(\"Mistral-Instruct-v2\")\n",
    "# mistral_vsm.load_vectors_from_tensor(embs, vocab)\n",
    "\n",
    "# uncomment if saving\n",
    "# torch.save((embs, vocab), \"../data/embeddings/Mistral-7B-Instruct-v0.2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:14<00:00,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# birds = lm.extract_representation([(\"bird\", \"bird\")], layer = \"all\")\n",
    "# len(birds)\n",
    "# lm.encode_text([\"bird\"])\n",
    "\n",
    "# embs = lm.extract_representation(query, layer = \"all\")\n",
    "\n",
    "layerwise = defaultdict(list)\n",
    "\n",
    "query_dl = DataLoader(query_pairs, batch_size = 16)\n",
    "\n",
    "for batch in tqdm(query_dl):\n",
    "    query = list(zip(*batch))\n",
    "\n",
    "    embs = lm.extract_representation(query, layer = \"all\")\n",
    "    for i, emb in enumerate(embs):\n",
    "        layerwise[i].extend(emb)\n",
    "\n",
    "layerwise = {k: torch.stack(v) for k,v in layerwise.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerwise_vsms = {k: vsm.VectorSpaceModel(f\"Mistral-Instruct-v2-layer-{k}\") for k,v in layerwise.items()}\n",
    "\n",
    "for i, vsm in layerwise_vsms.items():\n",
    "    vsm.load_vectors_from_tensor(layerwise[i], list(concept_space.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layerwise_vsms\n",
    "anchor_neighbors = defaultdict(list)\n",
    "for anchor in anchors:\n",
    "    space = hyponyms - anchor_children[anchor]\n",
    "    space = [c for c in space if c in concepts.keys()]\n",
    "\n",
    "    # sims = []\n",
    "    # for i, vsm in layerwise_vsms.items():\n",
    "    #     neighbors = \n",
    "    neighbors = layerwise_vsms[32].neighbor(anchor, k=len(space), space=space, names_only=True, ignore_first=False)\n",
    "    anchor_neighbors[anchor].extend(neighbors[0][: math.ceil(len(anchor_children[anchor])/2)])\n",
    "\n",
    "    non_neighbors = list(reversed(neighbors[0]))\n",
    "    anchor_neighbors[anchor].extend(non_neighbors[: math.ceil(len(anchor_children[anchor])/2)])\n",
    "\n",
    "anchor_neighbors = dict(anchor_neighbors)\n",
    "random.seed(42)\n",
    "anchor_neighbors = {k: random.sample(v, len(v)) for k, v in anchor_neighbors.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sample_triples = []\n",
    "for anchor, negative_samples in anchor_neighbors.items():\n",
    "    for ns in negative_samples:\n",
    "        negative_sample_triples.append((anchor, ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/things/things-mistralai_Mistral-7B-Instruct-v0.2_layer32_ns-triples.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"anchor\", \"hyponym\"])\n",
    "    for triple in negative_sample_triples:\n",
    "        writer.writerow(triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save anchor, every concept similarities\n",
    "anchor_concept_sims = defaultdict(list)\n",
    "for anchor in anchors:\n",
    "    space = hyponyms\n",
    "    space = [c for c in space if c in concepts.keys()]\n",
    "\n",
    "    neighbor_sims = layerwise_vsms[32].neighbor(anchor, k = len(space), space=space, ignore_first=False)\n",
    "    for concept, sim in neighbor_sims[0]:\n",
    "        anchor_concept_sims[(anchor, concept)].append(sim)\n",
    "\n",
    "anchor_concept_sims_csv = []\n",
    "for (anchor, concept), sims in anchor_concept_sims.items():\n",
    "    anchor_concept_sims_csv.append((anchor, concept, max(sims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56672"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anchor_concept_sims_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/things/things-mistralai_Mistral-7B-Instruct-v0.2_layer32_anchor_sims.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"anchor\", \"concept\", \"similarity\"])\n",
    "    for row in anchor_concept_sims_csv:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmisra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
